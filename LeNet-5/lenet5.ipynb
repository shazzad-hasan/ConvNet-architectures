{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lenet5.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNDhHH17glGRzbzncSALLZQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shazzad-hasan/training-reproducable-deep-learning-models/blob/main/LeNet-5/lenet5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/shazzad-hasan/training-reproducable-deep-learning-models.git"
      ],
      "metadata": {
        "id": "OJCVUQcLMxGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "GpeCttDQOCEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/training-reproducable-deep-learning-models/LeNet-5"
      ],
      "metadata": {
        "id": "CBxCXyu1OJxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "VDg8_ERjQZPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3BhppgxLNwx"
      },
      "outputs": [],
      "source": [
        "# import required libraries\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import local helper functions\n",
        "from helper_dataset import dataloader_mnist\n",
        "from helper_train import train\n",
        "from helper_evaluate import compute_loss_accuracy, set_all_seeds\n",
        "from helper_plot import show_examples, show_sample_test_result"
      ],
      "metadata": {
        "id": "BcCabuWGLgM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if cuda is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if train_on_gpu:\n",
        "  print(\"CUDA is available!\")\n",
        "else:\n",
        "  print(\"CUDA is not available\")\n",
        "\n",
        "if train_on_gpu:\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "cOrxjDC9OzMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# settings\n",
        "random_seed = 123\n",
        "valid_size = 0.2\n",
        "batch_size = 32\n",
        "num_epochs = 20\n",
        "\n",
        "set_all_seeds(random_seed)"
      ],
      "metadata": {
        "id": "WMwkMTjhtzcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "data_transform  = transforms.Compose([transforms.Resize((32, 32)),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.5,),(0.5,))]\n",
        "    \n",
        ")\n",
        "\n",
        "train_loader, valid_loader, test_loader, classes = dataloader_mnist(\n",
        "    batch_size = batch_size, \n",
        "    train_transform = data_transform,\n",
        "    test_transform = data_transform,\n",
        "    valid_size = valid_size\n",
        ")\n"
      ],
      "metadata": {
        "id": "ggXBhcju1M7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classes)\n",
        "num_class = len(classes)"
      ],
      "metadata": {
        "id": "QdPny5QtkrL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the dataset\n",
        "for images, labels in train_loader:  \n",
        "    print('Image batch dimensions:', images.shape)\n",
        "    print('Image label dimensions:', labels.shape)\n",
        "    print('Class labels of 10 examples:', labels[:10])\n",
        "    break"
      ],
      "metadata": {
        "id": "smVY0bKXgttH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LeNet5(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes, grayscale=False):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.grayscale = grayscale\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        in_channels = 1 if self.grayscale else 3\n",
        "\n",
        "        self.features = torch.nn.Sequential(nn.Conv2d(in_channels, 6, 5),\n",
        "                                            nn.Tanh(),\n",
        "                                            nn.MaxPool2d(2),\n",
        "                                            nn.Conv2d(6, 16, 5),\n",
        "                                            nn.Tanh(),\n",
        "                                            nn.MaxPool2d(2))\n",
        "\n",
        "        self.classifier = torch.nn.Sequential(nn.Linear(16*5*5, 120),\n",
        "                                              nn.Tanh(),\n",
        "                                              nn.Linear(120, 84),\n",
        "                                              nn.Tanh(),\n",
        "                                              nn.Linear(84, num_classes))\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        logits = self.classifier(x)\n",
        "        return logits\n",
        "\n",
        "model = LeNet5(num_classes=10, grayscale=True)\n",
        "# move model to the right device\n",
        "model.to(device)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "id": "wrqVVpFllZsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# specify loss\n",
        "criterion = nn.CrossEntropyLoss() # categorical cross-entropy loss\n",
        "\n",
        "params = model.parameters()\n",
        "optimizer = optim.SGD(params, lr=0.01)\n",
        "\n",
        "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, mode=\"min\")"
      ],
      "metadata": {
        "id": "MRISgjmWlZv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses, valid_losses = train(model, num_epochs, train_loader, valid_loader,\n",
        "                                   test_loader, optimizer, criterion, device) "
      ],
      "metadata": {
        "id": "7vU_ZbFKlZ1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "baJJ8z7WAvbj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}